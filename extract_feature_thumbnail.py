# -*- coding: utf-8 -*-
"""Extract_Feature_Thumbnail.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1C-GHhFxVdu1mpZ0Ya3HB4rlLsiV8vO87
"""

import pandas as pd

"""# 데이터 로드"""

datas = pd.read_csv('./result_without_undefined.csv')
datas.head()

thumnail_links = datas['thumbnail_link']
print(thumnail_links.shape)
thumnail_links.head()

"""# 이미지 링크 -> numpy 값으로 변환"""

from PIL import Image
from urllib import request
from io import BytesIO
import matplotlib.pyplot as plt
from keras.preprocessing.image import load_img, img_to_array
import numpy as np
def make_img_npy(urls):
#     url = str(thumnail_links[12])
    images = []
    for url in urls:
        try:
            res = request.urlopen(url).read()
        except:
            print(url)
            continue
        # Sample_Image = Image.open(BytesIO(res)).resize((150,150))
        Sample_Image = Image.open(BytesIO(res))
        img = img_to_array(Sample_Image)
        images.append(img)
    return np.array(images)
#     plt.imshow(Sample_Image)

size = thumnail_links.shape[0] // 200
X_imgs = make_img_npy(thumnail_links[0 : 200])
for i in range(1, size+ 1):
    imgs = make_img_npy(thumnail_links[i*200 : (i+1)*200])
    X_imgs = np.concatenate((X_imgs, imgs), axis=0)
print(X_imgs.shape)

from tensorflow.keras.models import Model
from tensorflow.python.keras.applications.vgg16 import VGG16, preprocess_input
from keras.applications import VGG16

conv_base = VGG16(weights='imagenet',
                  include_top=False,
                  input_shape=(90, 120, 3))
conv_base.summary()

"""## *여기서  'block4_conv1' 가 위 레이어 이름으로, 뽑아낼 특징 맵 임*  
## 원하면, 다른 layer를 넣자. (밑으로 갈 수록, 디테일 위 부분은 크게)
"""

model = Model(inputs = conv_base.input,outputs = conv_base.get_layer('block4_conv1').output)
model.summary()

"""# Feature 추출"""

X_imgs[:1].shape

size = X_imgs.shape[0] // 200
image = preprocess_input(X_imgs[0 : 200])
feature_map = model.predict(image)
for i in range(1, size+ 1):
    imgs = preprocess_input(X_imgs[i*200 : (i+1)*200])
    feature_map_ = model.predict(imgs)
    feature_map = np.concatenate((feature_map, feature_map_), axis=0)
print(feature_map.shape)

shape = feature_map.shape
shape

"""Feature -> Flatten: 1차원 리스트로 변환"""

image_features = np.reshape(feature_map, (shape[0], shape[1]*shape[2]*shape[3]))
image_features.shape

from sklearn.datasets import load_digits
from sklearn.manifold import MDS

X = image_features
embedding = MDS(n_components=20)
X_transformed = embedding.fit_transform(X)
X_transformed.shape

"""# 군집화 진행, (계층적 군집, Kmeans)"""

from sklearn.cluster import DBSCAN, KMeans, SpectralClustering, AgglomerativeClustering

# Hierarchical Clustering
def hierarchicalClustering(dataset, n_clusters, n_init = 10, linkage = 'ward', normalization='standard'):

    cluster_data = AgglomerativeClustering(n_clusters = n_clusters, linkage = linkage ).fit(dataset)
    return cluster_data
# Cluster Algorithm

def kmeans(dataset, n_clusters, n_init = 10, max_iter = 300, tol = 1e-4, normalization='standard'):

    cluster_data = KMeans(n_clusters=n_clusters, n_init = n_init, max_iter = max_iter, tol = tol).fit(dataset)
    return cluster_data

"""## 계층적 군집"""

hresult = hierarchicalClustering(X_transformed, 5)
hresult.labels_

"""## Kmeans 군집"""

kresult = kmeans(X_transformed, 10)
kresult.labels_

X = X_transformed
embedding = MDS(n_components=2)
X_transformed_2 = embedding.fit_transform(X)
X_transformed_2.shape

import pandas as pd
import matplotlib.pyplot as plt
# visualization

## KMEANS result
df = np.hstack([X_transformed_2, kresult.labels_.reshape(-1, 1)]) # x_scaled_ss 오른쪽에 1열 붙이기

num = 10
for i in range(num):
    df_ft = df[df[:,2]==i, :] # 클러스터 2 추출
    plt.scatter(df_ft[:, 0], df_ft[:, 1], label=f'cluster {i}', cmap='Pairs') # x, y, label, 색상
# matplotlib로 그래프 그리기


plt.xlabel('feature 0')
plt.ylabel('feature 1')
plt.legend()
plt.title("KMEANS result")
plt.show()

"""# 실루엣 점수

너무 낮게 나오는게.. 맘에 걸리네요}
"""

from sklearn.metrics import silhouette_samples,silhouette_score
def plotSilhouette(X, y_km):
    cluster_labels = np.unique(y_km.labels_)
    n_clusters = cluster_labels.shape[0]
    silhouette_vals = silhouette_score(X, y_km.labels_,metric='euclidean')
#     print(silhouette_vals)
    return silhouette_vals

res = plotSilhouette(X_imgs.reshape(11298, -1),hresult)
print(res)

res = plotSilhouette(X_imgs.reshape(11214, -1),kresult)
print(res)

"""## 데이터 저장"""

datas['thumbnail_link'] = kresult.labels_

datas['thumbnail_link'].head()

datas.to_csv('results_with_thumbnail_labeld.csv')