# -*- coding: utf-8 -*-
"""youtube.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZwRiT-6oX_Meofdidr_EufobLAnGT7TE
"""
from googleapiclient.discovery import build
import time
from pororo import Pororo
import pandas as pd
import numpy as np

video_list = list()
id_list = list()
channel_list = list()

api_obj = build('youtube', 'v3', developerKey='')

"""인기 동영상 수집"""

data = pd.read_csv("/content/KR_youtube_trending_data.csv")

trend_video = data['video_id']
trend_video = trend_video.to_list()

for i, id in enumerate(trend_video):
        video_info = api_obj.videos().list(part='id, snippet, contentDetails, statistics, topicDetails', id = id, regionCode='KR').execute()
        if len(video_info['items']) == 0:
          continue
        video_info = video_info['items'][0]

        subscribers = api_obj.channels().list(part='id, snippet, statistics, topicDetails', id = video_info['snippet']['channelId'].execute()
        subscribers = subscribers['items'][0]

        video_id = id
        title = video_info['snippet']['title']
        publishedAt = video_info['snippet']['publishedAt']
        channelId = video_info['snippet']['channelId']
        channelTitle = video_info['snippet']['channelTitle']
        if 'subscriberCount' in subscribers['statistics']:
          subscriber = subscribers['statistics']['subscriberCount']
        else:
          subscriber = False
        channel_description = subscribers['snippet']['description']
        channel_publishAt = subscribers['snippet']['publishedAt']
        videoCount = subscribers['statistics']['videoCount']
        if 'topicDetails' in subscribers:
          if 'topicCategories' in subscribers['topicDetails']:
            channel_topic = subscribers['topicDetails']['topicCategories']
          else:
            channel_topic = False
        else:
          channel_topic = False
        duration = video_info['contentDetails']['duration']
        categoryId = video_info['snippet']['categoryId']
        if 'topicDetails' in video_info:
          video_topic = video_info['topicDetails']
        else:
          video_topic = False
        if 'tags' in video_info['snippet']:
          tags = video_info['snippet']['tags']
        else:
          tags = False
        if 'viewCount' in video_info['statistics']:
          view_count = video_info['statistics']['viewCount']
        else:
          view_count = False
        if 'likeCount' in video_info['statistics']:
          likes = video_info['statistics']['likeCount']
          dislikes = video_info['statistics']['dislikeCount']
          ratings_disabled = False
        else:
          likes = 0
          dislikes = 0
          ratings_disabled = True
        if 'commentCount' in video_info['statistics']:
          comment_count = video_info['statistics']['commentCount']
          comments_disabled = False
        else:
          comment_count = 0
          comments_disabled = True
        thumbnail_link = video_info['snippet']['thumbnails']['default']['url']
        description = video_info['snippet']['description']
        video_list.append([video_id, title, publishedAt, description, tags, channelId, channelTitle, subscriber, channel_description, channel_publishAt, videoCount, channel_topic, duration, categoryId, video_topic, view_count, likes, dislikes, ratings_disabled, comment_count, comments_disabled, thumbnail_link])

df = pandas.DataFrame(video_list)
df.to_csv('trend_result.csv', header=['video_id', 'title', 'publishedAt', 'description', 'tags', 'channelId', 'channelTitle', 'subscribers', 'channel_description', 'channel_publishAt', 'videoCount', 'channel_topic','duration', 'categoryId', 'video_topic', 'view_count', 'likes', 'dislikes', 'ratings_disabled', 'comment_count', 'comments_disabled','thumbnail_link'], index=None, engine='xlsxwriter')

"""비인기 동영상 수집"""

after='2020-08-01T09:00:00Z'
befor='2021-05-14T09:00:00Z'

response = api_obj.search().list(part='id, snippet', location='35.95, 128.25', locationRadius='300km', regionCode='KR', relevanceLanguage='ko', maxResults = '50', order = 'date', publishedAfter = after, publishedBefore = befor, type='video').execute()

while response:
    for item in response['items']:
        id_list.append(item['id']['videoId'])
        channel_list.append(item['snippet']['channelId'])

    if 'nextPageToken' in response:
        response = api_obj.search().list(part='id, snippet', location='35.95, 128.25', locationRadius='300km', regionCode='KR', relevanceLanguage='ko', maxResults = '50', order = 'date', publishedAfter = befor, publishedBefore = after, pageToken=response['nextPageToken'], type='video').execute()
    else:
        break

for i in range(0, len(id_list)):
        video_info = api_obj.videos().list(part='id, snippet, contentDetails, statistics, topicDetails', id = id_list[i], regionCode='KR').execute()
        if len(video_info['items']) == 0:
          continue
        video_info = video_info['items'][0]

        subscribers = api_obj.channels().list(part='id, snippet, statistics, topicDetails', id = channel_list[i]).execute()
        subscribers = subscribers['items'][0]

        video_id = id_list[i]
        title = video_info['snippet']['title']
        publishedAt = video_info['snippet']['publishedAt']
        channelId = video_info['snippet']['channelId']
        channelTitle = video_info['snippet']['channelTitle']
        if 'subscriberCount' in subscribers['statistics']:
          subscriber = subscribers['statistics']['subscriberCount']
        else:
          subscriber = False
        channel_description = subscribers['snippet']['description']
        channel_publishAt = subscribers['snippet']['publishedAt']
        videoCount = subscribers['statistics']['videoCount']
        if 'topicDetails' in subscribers:
          if 'topicCategories' in subscribers['topicDetails']:
            channel_topic = subscribers['topicDetails']['topicCategories']
          else:
            channel_topic = False
        else:
          channel_topic = False
        duration = video_info['contentDetails']['duration']
        categoryId = video_info['snippet']['categoryId']
        if 'topicDetails' in video_info:
          video_topic = video_info['topicDetails']
        else:
          video_topic = False
        if 'tags' in video_info['snippet']:
          tags = video_info['snippet']['tags']
        else:
          tags = False
        if 'viewCount' in video_info['statistics']:
          view_count = video_info['statistics']['viewCount']
        else:
          view_count = False
        if 'likeCount' in video_info['statistics']:
          likes = video_info['statistics']['likeCount']
          dislikes = video_info['statistics']['dislikeCount']
          ratings_disabled = False
        else:
          likes = 0
          dislikes = 0
          ratings_disabled = True
        if 'commentCount' in video_info['statistics']:
          comment_count = video_info['statistics']['commentCount']
          comments_disabled = False
        else:
          comment_count = 0
          comments_disabled = True
        thumbnail_link = video_info['snippet']['thumbnails']['default']['url']
        description = video_info['snippet']['description']
        video_list.append([video_id, title, publishedAt, description, tags, channelId, channelTitle, subscriber, channel_description, channel_publishAt, videoCount, channel_topic, duration, categoryId, video_topic, view_count, likes, dislikes, ratings_disabled, comment_count, comments_disabled, thumbnail_link])

df = pandas.DataFrame(video_list)
df.to_csv('result.csv', header=['video_id', 'title', 'publishedAt', 'description', 'tags', 'channelId', 'channelTitle', 'subscribers', 'channel_description', 'channel_publishAt', 'videoCount', 'channel_topic','duration', 'categoryId', 'video_topic', 'view_count', 'likes', 'dislikes', 'ratings_disabled', 'comment_count', 'comments_disabled','thumbnail_link'], index=None, engine='xlsxwriter')

"""데이터 병합 및 라벨링"""

data = pd.read_csv("/content/results.csv")
data1 = pd.read_csv("/content/trend_results.csv")

data1['trend'] = np.zeros(len(data1))

data['trend'] = np.ones(len(data))

merge_data = pd.merge(data1,data, how='outer')

merge_data = merge_data.drop_duplicates(['video_id'], keep="first")   #인기동영상과 비인기동영상에서 중복 발생시, 비인기동영상 삭제

merge_data.to_csv("final_result.csv", index=None, engine='xlsxwriter')

id_list = data1['video_id'].tolist()
channel_list = data1['channelId'].tolist()

"""Duration 단위 변환"""

import pandas as pd
import numpy as np

result = pd.read_csv("/content/final_results.csv")

result = result[result['duration'] != 'P0D']

result = result.reset_index()

date = result['publishedAt']

date = date.str.replace(pat='Z', repl=r'', regex=True)

duration = result['duration']

duration = duration.str.replace(pat=r'PT', repl=r'', regex=True)

for i, du in enumerate(duration):
  if not 'S' in du:
    duration[i] = du + '00S'

for i, du in enumerate(duration):
  if not 'M' in du:
    duration[i] = '00M'+ du

for i, du in enumerate(duration):
  if not 'H' in du:
    duration[i] = '00H'+ du

for i in range(8354, len(duration)):
  if not 'S' in duration[i]:
    duration[i] = duration[i] + '00S'

for i in range(8354, len(duration)):
  if not 'M' in duration[i]:
    duration[i] = '00M' + duration[i]

for i in range(8354, len(duration)):
  if not 'H' in duration[i]:
    duration[i] = '00H'+ duration[i]

duration = duration.str.replace(pat=r'H', repl=r':', regex=True)

duration = duration.str.replace(pat=r'M', repl=r':', regex=True)

duration = duration.str.replace(pat=r'S', repl=r'', regex=True)

du = []

from datetime import datetime

base  = datetime.strptime("0:0:0", "%H:%M:%S")

for i, durate in enumerate(duration):
  durat = datetime.strptime(duration[i], "%H:%M:%S")
  durat = durat - base
  du.append(durat.seconds)

result['duration'] = du

"""Temperature 구하기"""

view = result['view_count']

temp = []

from datetime import datetime

base  = datetime.strptime("20210514", "%Y%m%d")

for i, dat in enumerate(date):
  date_to_compare = datetime.strptime(date[i], "%Y-%m-%d %H:%M:%S")
  date_diff = base - date_to_compare

  temp.append(round(view[i]/date_diff.seconds, 2))

temp_data = pd.DataFrame(temp)

result['temperature'] = temp

"""제목의 감성 구하기"""
from pororo import Pororo
sa = Pororo(task="sentiment", model="brainbert.base.ko.nsmc", lang="ko")
sentiment=[]

for i in title:
  sentiment.append(sa(i))

result['sentiment']=sentiment
                                              
"""description 유무"""
                                              
description=result['description']
dd=description.replace(np.nan,0)
count=0
description1=[]
for i in dd:
  if i==0:
    count+=1
    description1.append(0)
  else:
    description1.append(1)
result['description1']=description1

"""tag 개수"""

tag=result['tags']
tag_num=[]

for i in tag:
  if i==False:
    tag_num.append(0)
  else:
    tag_num.append(len(i.split(',')))

result['tag_num']=tag_num
                                                                                      

"""결측치 제거"""

second=result[result['comments_disabled']==False]

second = second[second['ratings_disabled']==False]

second = second[second['subscribers']!=0]

second.to_csv("results.csv", index=None)

"""워드 임베딩"""

se = Pororo(task="sentence_embedding", lang="ko")

sentence = []

result = pd.read_csv("/content/results.csv")

title = result['title']

title = title.to_list()

for i, sen in enumerate(title):
  sentence.append(se(sen))

from sklearn.decomposition import PCA

pca = PCA(n_components=1)
pca.fit(sentence)

pca = PCA(n_components=10)

X_reduced = pca.fit_transform(sentence)

column = ['Title_Embedding1', 'Title_Embedding2', 'Title_Embedding3', 'Title_Embedding4', 'Title_Embedding5', 'Title_Embedding6', 'Title_Embedding7', 'Title_Embedding8', 'Title_Embedding9', 'Title_Embedding10']

result2 = pd.DataFrame(X_reduced, columns=column)

result3 = pd.concat([result, result2], axis=1)

result3.to_csv("results.csv", index=None)

